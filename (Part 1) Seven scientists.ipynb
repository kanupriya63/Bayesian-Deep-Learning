{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27921d2d",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010aa8d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af8fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb01ea531f1f7bb0fe9eca67e3700485",
     "grade": false,
     "grade_id": "cell-a03d5258a5a4712b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb402ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6c06385802fd161475d774b16872807",
     "grade": false,
     "grade_id": "cell-511cf022784e1b68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: The seven scientists\n",
    "\n",
    "This example is due to [MacKay 2003, exercise 22.15] and [Lee & Wagenmaker 2013, section 4.2].\n",
    "\n",
    "Suppose seven scientists all go and perform the same experiment, each collecting a measurement $x_i$ for $i = 1,\\dots,7$, of an underlying physical value $\\mu$. \n",
    " \n",
    "These scientists are varyingly good at their job, and while we can assume each scientist would estimate $\\mu$ correctly _on average_, some of them may have much more error in their measurements than others.\n",
    "\n",
    "They come back with the following seven observations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb981a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0ca7f1533c8b4d0dbc50aafffd037e7",
     "grade": false,
     "grade_id": "cell-aac9438530921a9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "measurements = torch.FloatTensor([-27.020, 3.570, 8.191, 9.898, 9.603, 9.945, 10.056])\n",
    "\n",
    "plt.bar(np.arange(1,8), measurements) # , \"o\")\n",
    "plt.xlabel(\"Which scientist\")\n",
    "plt.ylabel(\"Recorded measurement $x_i$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8889bcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0e47cdf0a576927cbd40260a745a76b",
     "grade": false,
     "grade_id": "cell-5fb5d4bb3d16a5ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From looking at the plot, clearly one scientist does not know what they are doing (and some of the others are probably a little suspect too)!\n",
    "\n",
    "\n",
    "### A model for the data\n",
    "\n",
    "In this exercise we will suppose that there is \"scientist-specific\" standard deviation $\\sigma_i$, which describes how accurately each of them might perform the experiment:\n",
    "\n",
    "$$\\begin{align}\n",
    "x_i &\\sim \\mathrm{Normal}(\\mu, \\sigma_i^2).\n",
    "\\end{align}$$\n",
    "\n",
    "Scientists with low $\\sigma_i$ produce good estimates of $x$, whereas scientists with high $\\sigma_i$ might have wildly inaccurate estimates. However, we don't know _which_ scientists are good -- and we only have one observation from each!\n",
    "\n",
    "We can ask two questions:\n",
    "\n",
    "* What is the \"real\" value of $\\mu$?\n",
    "* What are the values of $\\sigma_i$ for each scientists?\n",
    "\n",
    "\n",
    "\n",
    "### Bayesian inference approach\n",
    "\n",
    "You will have to choose priors for the mean $\\mu$ of the measurements, and for the error standard deviation $\\sigma\\_i$ for each of the $i$ scientists. A good starting point is\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mu &\\sim \\mathrm{Normal}(0, \\alpha^2) \\\\\n",
    "\\sigma_i &\\sim \\mathrm{Exponential}(\\beta)\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\alpha=50$ and $\\beta=0.5$. This is a prior distribution with mean 2 that places diminishing probability density on larger values of $\\sigma_i$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(np.linspace(0.01,10,100), 0.0, \n",
    "                 dist.Exponential(rate=0.5).log_prob(torch.linspace(0.01,10,100)).exp(), \n",
    "                 edgecolor='k');\n",
    "plt.xlabel(\"$\\sigma$\")\n",
    "plt.ylabel(\"$p(\\sigma)$\")\n",
    "plt.title(\"Exponential distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15d615",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe7833adda1e89ad664603dc020f69e0",
     "grade": false,
     "grade_id": "cell-76565ec244b833cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TASK #1 (3 points): Define the model\n",
    "\n",
    "Given $\\alpha=50, \\beta=0.5$, and the measurements $x$ above, write a function to compute the unnormalized log density\n",
    "\n",
    "$$\\log p(\\mu, x_1,\\dots,x_7, \\sigma_1,\\dots, \\sigma_7 | \\alpha, \\beta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacbaa9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4de3761990e778559755a44a608e191c",
     "grade": false,
     "grade_id": "A-log-joint",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_joint(mu, sigma, alpha=50, beta=0.5):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    mu    : scalar\n",
    "    sigma : tensor, vector of length 7. Should have sigma > 0\n",
    "    alpha : scalar, standard deviation of Gaussian prior on mu. Default to 50\n",
    "    beta  : scalar, rate of exponential prior on sigma_i. Default to 0.5\n",
    "\n",
    "    OUTPUT:\n",
    "    log_joint: the log probability log p(mu, sigma, x | alpha, beta), scalar\n",
    "    \n",
    "    NOTE: For inputs where sigma <= 0, please return negative infinity!\n",
    "\n",
    "    \"\"\"\n",
    "    assert mu.ndim == 0\n",
    "    assert sigma.shape == (7,)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    l_prior = dist.Normal(mu,alpha).log_prob(mu)+dist.Exponential(beta).log_prob(sigma).sum(0)\n",
    "    l_likelihood = dist.Normal(mu,sigma).log_prob(measurements).sum(0)\n",
    "    l_joint = l_prior + l_likelihood\n",
    "    return l_joint\n",
    "    #raise NotImplementedError()\n",
    "    # return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d7759",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b4a12aa7efb35e1a73a7abcef08b142",
     "grade": false,
     "grade_id": "cell-3b0c10a0da8379c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Ignore the following cells. \n",
    "\n",
    "They consist of \"hidden\" test cases, and are used by the grading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3e2c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01534910f43b83766d73e89227fa69e7",
     "grade": true,
     "grade_id": "A-joint-test-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2b54b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb345e53764374ff9eff52b230f04db0",
     "grade": true,
     "grade_id": "A-joint-test-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7dd96",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95577a162c9b2402a8120812f78e47ff",
     "grade": false,
     "grade_id": "cell-9ff091743af7696f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TASK #2 (5 points): Implement an MCMC sampler\n",
    "\n",
    "Your second task is to implement an MCMC algorithm to sample from the posterior distribution\n",
    "\n",
    "$$p(\\mu, \\sigma | x, \\alpha, \\beta).$$\n",
    "\n",
    "To do this, you need to implement two functions:\n",
    "\n",
    "* `get_mcmc_proposal`: this takes in current values of $\\mu$ and $\\sigma$, and returns pytorch `Distribution` objects (i.e., `torch.distributions.Distribution`, here in-scope as `dist.Distribution`) that will propose a next value given the current value, $q(\\mu' | \\mu, \\dots)$ and $q(\\sigma' | \\sigma, \\dots)$. It is **your choice** what sort of distribution to use here! Just make sure that whatever you propose works well in your MCMC algorithm.\n",
    "\n",
    "* `mcmc_step`: this takes in current values of $\\mu$ and $\\sigma$, and runs a single Metropolis-Hastings step:\n",
    "  1. sample candidate values from the proposal distribution you defined\n",
    "  2. compute an acceptance probability, and either accept or reject\n",
    "  3. return $\\mu, \\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4649aaa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fd5469053a4eecb0e68921a1b37b4db",
     "grade": false,
     "grade_id": "A-proposal",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_mcmc_proposal(mu, sigma):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    mu    : scalar\n",
    "    sigma : tensor, vector of length 7. Should have sigma > 0\n",
    "\n",
    "    OUTPUT:\n",
    "    q_mu    : instance of Distribution class, that defines a proposal for mu\n",
    "    q_sigma : instance of Distribution class, that defines a proposal for sigma\n",
    "    \"\"\"\n",
    "    \n",
    "    q_mu = dist.Normal(mu,0.4)\n",
    "    q_sigma = dist.Normal(sigma,0.2)\n",
    "    return q_mu, q_sigma\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    # return q_mu, q_sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f5b87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95c0b3019589bd5ba7b0c50736e31407",
     "grade": false,
     "grade_id": "cell-fd65b5fbc382f0a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Quick self-check!\n",
    "\n",
    "If your `get_mcmc_proposal` has the correct function signature, all the following assertions should be true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a736bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mu, q_sigma = get_mcmc_proposal(torch.tensor(9.0), torch.ones(7))\n",
    "assert isinstance(q_mu, dist.Distribution)\n",
    "assert isinstance(q_sigma, dist.Distribution)\n",
    "assert q_mu.sample().shape == ()\n",
    "assert q_sigma.sample().shape == (7,)\n",
    "del q_mu, q_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678ac66",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc2956aaea02d4a5c8655851e379cb9c",
     "grade": false,
     "grade_id": "A-mcmc-step",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mcmc_step(mu, sigma, alpha=50, beta=0.5):\n",
    "    \"\"\"\n",
    "    mu    : scalar\n",
    "    sigma : tensor, vector of length 7. Should have sigma > 0\n",
    "    alpha : scalar, standard deviation of Gaussian prior on mu. Default to 50\n",
    "    beta  : scalar, rate of exponential prior on sigma_i. Default to 0.5\n",
    "\n",
    "    OUTPUT:\n",
    "    mu       : the next value of mu in the MCMC chain\n",
    "    sigma    : the next value of sigma in the MCMC chain\n",
    "    accepted : a boolean value, indicating whether the proposal was accepted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    accepted = False\n",
    "    q_mu, q_sigma = get_mcmc_proposal(mu, sigma)\n",
    "    \n",
    "    c_mu = q_mu.sample() #current mu\n",
    "    c_sigma= q_sigma.sample() #current sigma\n",
    "    \n",
    "    try:\n",
    "        prob_new = log_joint(c_mu,c_sigma)\n",
    "    except ValueError :\n",
    "        prob_new = -torch.inf\n",
    "    \n",
    "    prob_old = log_joint(mu,sigma)\n",
    "    \n",
    "    if prob_new - prob_old > torch.rand(1).log().item() :\n",
    "        accepted = True\n",
    "        return c_mu, c_sigma, accepted\n",
    "    else:\n",
    "        return mu, sigma, accepted\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    # return mu, sigma, accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1cf63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a1abe7ca3f3ef535477bd5d5cddc453",
     "grade": false,
     "grade_id": "cell-e2ff98a61b7aa19b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Running MCMC\n",
    "\n",
    "We've supplied the outer loop for you -- it will call and execute your `mcmc_step` function. You should *not* need to edit it!\n",
    "\n",
    "You do need to fill in the function `algo_parameters`, though, which just returns the total number of iterations you decide to run the MCMC chain, and the number of samples to discard as \"burnin\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6c1a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ff262f1c9b0b1df58ae39ded7dfa629",
     "grade": false,
     "grade_id": "cell-031b459637e282d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def run_mcmc(N_iters, mu_init, sigma_init):\n",
    "    \"\"\" Run an MCMC algorithm for a fixed number of iterations \"\"\"\n",
    "    \n",
    "    mu_chain = [mu_init]\n",
    "    sigma_chain = [sigma_init]\n",
    "    N_accepted = 0\n",
    "    for _ in range(N_iters):\n",
    "        mu, sigma, accepted = mcmc_step(mu_chain[-1], sigma_chain[-1])\n",
    "        mu_chain.append(mu)\n",
    "        sigma_chain.append(sigma)\n",
    "        N_accepted += accepted\n",
    "    \n",
    "    return torch.stack(mu_chain), torch.stack(sigma_chain), N_accepted / N_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3b8c2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00c190aa583f92ebdf549d70df03a3fc",
     "grade": false,
     "grade_id": "A-params",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def algo_parameters():\n",
    "    \"\"\" TODO: set these to appropriate values:\n",
    "    \n",
    "    OUTPUT:\n",
    "    N_samples : total number of MCMC steps\n",
    "    N_burnin  : number of initial steps to discard\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    N_samples = 10000\n",
    "    N_burnin = 1000\n",
    "    return N_samples, N_burnin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9898658",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d797752682ce17920464bf716a3f95a4",
     "grade": false,
     "grade_id": "cell-5f34ae3b6d35a5f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Initialize, run, and display diagnostics\n",
    "\n",
    "The following code initializes the MCMC sampler, executes it for the number of iterations you specified, and then plots a handful of diagnostics.\n",
    "\n",
    "Use these diagnostics to decide whether or not you have done this properly! Take some time to try to interpret the results, and feel free to play around with the plots a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_init = measurements.mean()\n",
    "sigma_init = torch.ones(7)\n",
    "\n",
    "N_samples, N_burnin = algo_parameters()\n",
    "\n",
    "mu_chain, sigma_chain, accepted = run_mcmc(N_samples, mu_init, sigma_init)\n",
    "print(\"acceptance rate:\", accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_chain);\n",
    "plt.xlabel(\"MCMC iteration\");\n",
    "plt.ylabel(\"$\\mu$\")\n",
    "plt.figure();\n",
    "plt.hist(mu_chain[N_burnin:].numpy(), bins=20);\n",
    "plt.xlabel(\"$\\mu$\")\n",
    "plt.ylabel(\"Counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37197b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4));\n",
    "plt.plot(sigma_chain)\n",
    "plt.legend(range(1,8));\n",
    "plt.xlabel(\"MCMC iteration\")\n",
    "plt.ylabel(\"$\\sigma_i$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(sigma_chain[N_burnin:].T, positions=np.arange(1, 8));\n",
    "plt.xlabel(\"Which scientist\")\n",
    "plt.ylabel(\"Estimated measurement std $\\sigma_i$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd165ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa7a29c99ce5c3afafc4422be2806a2a",
     "grade": false,
     "grade_id": "cell-7787abc405bb90dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TASK #3 (2 points): Estimate posterior expectations\n",
    "\n",
    "We're specifically interested in using the samples to answer the following:\n",
    "\n",
    "1. What is the expected value of $\\mu$, i.e., $\\mathbb{E}[\\mu ]$, under the posterior distribution?\n",
    "2. What is the posterior probability that $\\mu$ is less than 9, i.e. $\\Pr(\\mu < 9.0)$?\n",
    "\n",
    "Both of these questions can be answered by using samples from your MCMC chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cab82c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f8f015c4b819ae529df5b3453b2b5a2",
     "grade": false,
     "grade_id": "A-posterior",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_E_mu(mu_chain, sigma_chain, N_burnin):\n",
    "    \"\"\" Estimate E[mu] \n",
    "    \n",
    "    INPUTS:\n",
    "    mu_chain    : sequence of MCMC samples of mu\n",
    "    sigma_chain : sequence of MCMC samples of sigma \n",
    "    N_burnin    : number of initial MCMC samples to discard as burnin \n",
    "    \n",
    "    OUTPUTS:\n",
    "    mu : expected value of mu (scalar)\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    mu = torch.mean(mu_chain[N_burnin:])\n",
    "    return mu\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "            \n",
    "def estimate_pr_mu_lt_9(mu_chain, sigma_chain, N_burnin):\n",
    "    \"\"\" Estimate the posterior probability that mu is less than 9, i.e. Pr(mu < 9) \n",
    "    \n",
    "    INPUTS:\n",
    "    mu_chain    : sequence of MCMC samples of mu\n",
    "    sigma_chain : sequence of MCMC samples of sigma \n",
    "    N_burnin    : number of initial MCMC samples to discard as burnin \n",
    "    \n",
    "    OUTPUTS:\n",
    "    estimate : estimate of Pr(mu < 9), a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    estimate = dist.Normal(estimate_E_mu(mu_chain,sigma_chain,N_burnin),torch.tensor(0.4)).cdf(torch.tensor(9))\n",
    "    return estimate\n",
    "            \n",
    "    #raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0d556",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26f35c5a0de3ea363bbdab58feff1cf4",
     "grade": false,
     "grade_id": "cell-1e617c83f015c8ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"E[mu] = %0.4f\" % estimate_E_mu(mu_chain, sigma_chain, N_burnin))\n",
    "print(\"Pr(mu < 9) = %0.4f\" % estimate_pr_mu_lt_9(mu_chain, sigma_chain, N_burnin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd87f00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c0f10bab102e6af6e1c97b68a5ffd13",
     "grade": false,
     "grade_id": "cell-1b69f7842daf1376",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Ignore the following cells. They are used by the grading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb73b0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e13c8c0111e40122eb765bd297ac7fe3",
     "grade": true,
     "grade_id": "A-mcmc-test-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b77ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3ec8fa9669826dfe9d99e8b578b007b",
     "grade": true,
     "grade_id": "A-mcmc-test-2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326770f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ec7e87515d26e5d24dca7245500be9",
     "grade": true,
     "grade_id": "A-mcmc-test-3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f5f85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "476eba7affce66e07808ff1f59b08ecd",
     "grade": true,
     "grade_id": "A-expectation-test-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6490cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "509a1ba9d2dc35e1c989181516849c1f",
     "grade": true,
     "grade_id": "A-expectation-test-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198ef02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d82313e085c1ee49c9cf29e52d30c302",
     "grade": false,
     "grade_id": "cell-bfbfd2612938a02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# EXTRA CREDIT TASK #4 (4 points): Estimate $\\alpha$ and $\\beta$\n",
    "\n",
    "Did we choose the hyperparameters $\\alpha$ and $\\beta$ well? Or were these poor selections?\n",
    "\n",
    "One way of checking whether $\\alpha$ and $\\beta$ are set well is by computing a marginal likelihood estimate, i.e. estimating $p(x | \\alpha, \\beta)$ for different choices of $\\alpha, \\beta$.\n",
    "\n",
    "However, a different option is to *also* perform Bayesian inference over $\\alpha$ and $\\beta$! To do this, we need to do three things:\n",
    "\n",
    "1. Define a prior $p(\\alpha, \\beta)$\n",
    "2. Define MCMC proposals $q(\\alpha' | \\alpha)$ and $q(\\beta' | \\beta)$\n",
    "3. Update the MCMC algorithm itself to also sample $\\alpha, \\beta$.\n",
    "\n",
    "To do this, this involves targeting the joint probability distribution\n",
    "\n",
    "$$p(x,\\mu,\\sigma,\\alpha,\\beta) = p(x | \\mu, \\sigma)p(\\mu | \\alpha)p(\\sigma | \\beta)p(\\alpha)p(\\beta).$$\n",
    "\n",
    "You can write your MCMC algorithm so that it alternates between doing updates on $\\mu, \\sigma$ (using your existing `mcmc_step` function) and doing updates on $\\alpha, \\beta$ (using a new `mcmc_step_hyperparams` function).\n",
    "\n",
    "To do this you need to implement two things:\n",
    "\n",
    "1. `log_prior_alpha_beta`: given $\\alpha,\\beta$, return $\\log p(\\alpha, \\beta)$. You are free to define whatever sort of prior you think is appropriate.\n",
    "2. `mcmc_step_hyperparams`: do a single MCMC step (including accept / reject) to update $\\alpha, \\beta$.\n",
    "\n",
    "These will then be called by the `run_mcmc_bonus` function, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b37be",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09cf5a586eca3f42cb9e069785532b6f",
     "grade": false,
     "grade_id": "A-ec-prior",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_prior_alpha_beta(alpha, beta):\n",
    "    \"\"\"\n",
    "    Define a prior distribution on alpha, beta, and return its log probability\n",
    "    \n",
    "    INPUT:\n",
    "    alpha : scalar, standard deviation of Gaussian distribution on mu\n",
    "    beta  : scalar, rate of exponential distribution on sigma_i\n",
    "\n",
    "    OUTPUT:\n",
    "    log_prob : scalar, `log p(alpha, beta)`\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8861d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09e9aac352b0a3a1a61cd4ebedf64399",
     "grade": false,
     "grade_id": "A-ec-step",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mcmc_step_hyperparams(mu, sigma, alpha, beta):\n",
    "    \"\"\"\n",
    "    Run an MCMC step on alpha and beta\n",
    "    \n",
    "    INPUT:\n",
    "    mu    : scalar\n",
    "    sigma : tensor, vector of length 7. Should have sigma > 0\n",
    "    alpha : scalar, standard deviation of Gaussian distribution on mu\n",
    "    beta  : scalar, rate of exponential distribution on sigma_i\n",
    "\n",
    "    OUTPUT:\n",
    "    alpha    : the next value of alpha in the MCMC chain\n",
    "    beta     : the next value of beta in the MCMC chain\n",
    "    accepted : a boolean value, indicating whether the proposal was accepted\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # return alpha, beta, accepted\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89ae56",
   "metadata": {},
   "source": [
    "### Run this MCMC algorithm, and plot the results.\n",
    "\n",
    "What do you think?\n",
    "\n",
    "1. Are these results qualitatively different?\n",
    "2. Were the original choices of $\\alpha, \\beta$ reasonable?\n",
    "3. How sensitive are these results to $\\alpha, \\beta$? To $p(\\alpha, \\beta)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30946ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6d0eed6af5138e5d199739a62d2238a",
     "grade": false,
     "grade_id": "cell-6b09d7e3423ba42f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def run_mcmc_bonus(N_iters, mu_init, sigma_init, alpha_init, beta_init):\n",
    "    \"\"\" Run an MCMC algorithm for a fixed number of iterations.\n",
    "    \n",
    "    This also runs MCMC on \"hyperparameters\" alpha and beta.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    mu_chain = [mu_init]\n",
    "    sigma_chain = [sigma_init]\n",
    "    alpha_chain = [alpha_init]\n",
    "    beta_chain = [beta_init]\n",
    "    for _ in range(N_iters):\n",
    "        alpha, beta, accepted = mcmc_step_hyperparams(mu_chain[-1], sigma_chain[-1], alpha_chain[-1], beta_chain[-1])\n",
    "        alpha_chain.append(alpha)\n",
    "        beta_chain.append(beta)\n",
    "\n",
    "        mu, sigma, accepted = mcmc_step(mu_chain[-1], sigma_chain[-1], alpha_chain[-1], beta_chain[-1])\n",
    "        mu_chain.append(mu)\n",
    "        sigma_chain.append(sigma)\n",
    "    \n",
    "    return torch.stack(mu_chain), torch.stack(sigma_chain), torch.stack(alpha_chain), torch.stack(beta_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mu_chain, new_sigma_chain, alpha_chain, beta_chain = run_mcmc_bonus(N_samples, mu_chain[-1], sigma_chain[-1], torch.tensor(50.0), torch.tensor(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_chain)\n",
    "plt.plot(alpha_chain);\n",
    "plt.plot(beta_chain);\n",
    "plt.legend(['mu', 'alpha', 'beta']);\n",
    "plt.xlabel(\"Iteration\");\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.hist(alpha_chain[N_burnin:].numpy(), bins=20, density=True);\n",
    "plt.xlabel(\"$\\\\alpha$\")\n",
    "plt.ylabel(\"$p(\\\\alpha)$\")\n",
    "plt.subplot(122)\n",
    "plt.hist(beta_chain[N_burnin:].numpy(), bins=20, density=True);\n",
    "plt.xlabel(\"$\\\\beta$\")\n",
    "plt.ylabel(\"$p(\\\\beta)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878809dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(new_mu_chain[N_burnin:].numpy(), bins=20, density=True);\n",
    "plt.xlabel(\"$\\mu$\")\n",
    "plt.ylabel(\"$p(\\mu)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45646bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(new_sigma_chain[N_burnin:].T, positions=np.arange(1, 8));\n",
    "plt.xlabel(\"Which scientist\")\n",
    "plt.ylabel(\"Estimated measurement std $\\sigma_i$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9225f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7495b774181ea9832ee2a1cf890c26d",
     "grade": true,
     "grade_id": "A-ec-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b468c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d39d8e9f0cf197f4b4100747a746b728",
     "grade": true,
     "grade_id": "A-ec-2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# (GRADING)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
