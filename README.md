# Bayesian-Deep-Learning

The following project is done as part of a coursework for the module COMP0171 - Bayesian Deep Learning taught at UCL.

In **Part 1**, we fit a variational autoencoder to the MNIST dataset. The dataset has also been added to the repository.

In **Part 2**, we implement stochastic gradient Langevin dynamics for sampling from a Bayesian neural network and break down the variance to estimate epistemic and aleatoric uncertainty. For this, we use two_moon data set which is already added to the repository.

In **Part 3**, we fit a Bayesian logistic regression model and perform MAP estimation (penalized maximum likelihood) and Laplace approximation (a Gaussian approximate posterior, centered at the mode).
